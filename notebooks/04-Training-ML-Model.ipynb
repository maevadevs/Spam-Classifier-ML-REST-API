{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3965152a",
   "metadata": {},
   "source": [
    "# Training ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3361c",
   "metadata": {},
   "source": [
    "For training our ML model, we will use Google Colab as it offers Free GPUs for training models\n",
    "\n",
    "- Google Colab Notebook: https://colab.research.google.com/drive/1S3LjzvbDs1FK1UTYXRdMtHOsVGxvz9wM?usp=sharing\n",
    "- Reference Blog Post: https://www.codingforentrepreneurs.com/blog/build-a-spam-classifier-with-keras\n",
    "\n",
    "The matching code on the Google Colab Notebook is copied below as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ab3525",
   "metadata": {},
   "source": [
    "## Load the Previously Saved  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a548b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# For Tokenizing texts\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# For uniforming our token vectors\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Keras Models\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89b85e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets directories\n",
    "PROJ_DIR = Path().resolve().parent\n",
    "DATASETS_DIR = os.path.join(PROJ_DIR, \"datasets\")\n",
    "EXPORTS_DIR = os.path.join(DATASETS_DIR, \"exports\")\n",
    "METADATA_PKL_PATH = os.path.join(EXPORTS_DIR, \"spam-metadata.pkl\")\n",
    "TOKENIZER_JSON_PATH = os.path.join(EXPORTS_DIR, \"spam-tokenizer.json\")\n",
    "MODEL_EXPORT_PATH = os.path.join(EXPORTS_DIR,\"spam-ml-model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a147e3",
   "metadata": {},
   "source": [
    "**Warning About `pickle`**\n",
    "\n",
    "- It is possible for outputs of `pickle` to contain malicious data\n",
    "- If someone gives you a pickle file, be wary of where it came from or you might infest your system\n",
    "- Only run pickle files from trusted sources\n",
    "  - It is fine if you are the one manipulating the data so you know where the data came from\n",
    "  - But do not use pickle file from someone else\n",
    "  - Another option is to simply ask them as `csv` files\n",
    "  \n",
    "In this case, we generated this pickle file earlier so we can make use of it ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667f83b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_train': array([[  0,   0,   0, ..., 151,  15,  11],\n",
       "        [  0,   0,   0, ...,  15,   5, 159],\n",
       "        [  0,   0,   0, ...,  72, 104,  83],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,  62, 220, 160],\n",
       "        [  0,   0,   0, ...,   0,   0,  47],\n",
       "        [  0,   0,   0, ...,   7, 102,  19]]),\n",
       " 'X_test': array([[  0,   0,   0, ...,   1, 152,  26],\n",
       "        [  0,   0,   0, ...,  71,  41, 149],\n",
       "        [  0,   0,   0, ...,  30,  34,   7],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,  11,   6,  13],\n",
       "        [  0,   0,   0, ...,   0,  76,  10],\n",
       "        [  0,   0,   0, ...,   8, 142, 185]]),\n",
       " 'y_train': array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'y_test': array([[0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]], dtype=float32),\n",
       " 'max_num_words': 280,\n",
       " 'max_sequence_length': 300,\n",
       " 'labels_to_int_mapping': {'ham': 0, 'spam': 1},\n",
       " 'int_to_labels_mapping': {0: 'ham', 1: 'spam'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the pickle file exported from previous step\n",
    "pickle_data = {}\n",
    "\n",
    "with open(METADATA_PKL_PATH, 'rb') as f:\n",
    "    pickle_data = pickle.load(f)\n",
    "    \n",
    "# Preview the data\n",
    "display(pickle_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aad020",
   "metadata": {},
   "source": [
    "We can transform the extracted data back into what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b414d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform pickle_data back to useful Data Frames\n",
    "X_train = pickle_data[\"X_train\"]\n",
    "X_test = pickle_data[\"X_test\"]\n",
    "y_train = pickle_data[\"y_train\"]\n",
    "y_test = pickle_data[\"y_test\"]\n",
    "\n",
    "MAX_NUM_WORDS = pickle_data[\"max_num_words\"]\n",
    "MAX_SEQUENCE_LENGTH = pickle_data[\"max_sequence_length\"]\n",
    "\n",
    "labels_to_int_mapping = pickle_data[\"labels_to_int_mapping\"]\n",
    "int_to_labels_mapping = pickle_data[\"int_to_labels_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ad066e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x1dc83e22910>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also re-load the tokenizer\n",
    "with open(TOKENIZER_JSON_PATH) as json_file:\n",
    "    tokenizer_data = json.load(json_file)\n",
    "    tokenizer = Tokenizer(tokenizer_data)\n",
    "    \n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0782e3c",
   "metadata": {},
   "source": [
    "## Create our LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a53303",
   "metadata": {},
   "source": [
    "This is a Keras Model for classification problems\n",
    "\n",
    "- Most of this is based on Keras Documentation\n",
    "- This is one of the best model for the cross-category classification: `categorical_crossentropy`\n",
    "  - Works for 2 labels or more\n",
    "- Key things:\n",
    "  - `MAX_NUM_WORDS`\n",
    "  - `input_length` - Must be all of the same length (Uniform Matrix)\n",
    "  - `LSTM` - A common model for text-related data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d4a4c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 128)          35840     \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 300, 128)         0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 196)               254800    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 394       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 291,034\n",
      "Trainable params: 291,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "# Create the Model\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers on Model\n",
    "model.add(Embedding(\n",
    "    MAX_NUM_WORDS, \n",
    "    embed_dim, \n",
    "    input_length = X_train.shape[1]\n",
    "))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(\n",
    "    lstm_out, \n",
    "    dropout = 0.3, \n",
    "    recurrent_dropout = 0.3\n",
    "))\n",
    "model.add(Dense(\n",
    "    2, # We only have 2 labels: Spam or Ham\n",
    "    activation = \"softmax\"\n",
    "))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss = \"categorical_crossentropy\", \n",
    "    optimizer = \"adam\", \n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Check the final result\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9406fa",
   "metadata": {},
   "source": [
    "After creating the model, we can start fitting it on our data\n",
    "\n",
    "**Note**: Keras is doing validation while training\n",
    "\n",
    "- Often, we would want a final validation set for confirming our final model\n",
    "- For our demo-purpose here, we do not have that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94236fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "158/158 [==============================] - 163s 1s/step - loss: 0.2918 - accuracy: 0.8830 - val_loss: 0.1682 - val_accuracy: 0.9412\n",
      "Epoch 2/5\n",
      "158/158 [==============================] - 156s 986ms/step - loss: 0.1437 - accuracy: 0.9534 - val_loss: 0.1497 - val_accuracy: 0.9545\n",
      "Epoch 3/5\n",
      "158/158 [==============================] - 160s 1s/step - loss: 0.1214 - accuracy: 0.9607 - val_loss: 0.1361 - val_accuracy: 0.9553\n",
      "Epoch 4/5\n",
      "158/158 [==============================] - 150s 948ms/step - loss: 0.1159 - accuracy: 0.9615 - val_loss: 0.1321 - val_accuracy: 0.9581\n",
      "Epoch 5/5\n",
      "158/158 [==============================] - 156s 989ms/step - loss: 0.1270 - accuracy: 0.9548 - val_loss: 0.2094 - val_accuracy: 0.9163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dcada33df0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on our data\n",
    "# WARNING: This can take a while and consume computing-power\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data = (X_test, y_test), # Keras is doing validation while training\n",
    "    batch_size = batch_size, \n",
    "    verbose = 1, \n",
    "    epochs = epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc06465",
   "metadata": {},
   "source": [
    "Finally, we want to export the trained model into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb7e8c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model into h5 file\n",
    "model.save(str(MODEL_EXPORT_PATH))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
